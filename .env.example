# Quadcopter Tracking Research Environment Configuration
# Copy to .env and customize values as needed
# All values have sensible defaults; only override what you need to change
#
# SECURITY WARNING: This file is an EXAMPLE only. Never commit your real .env
# file to version control. The .env file is gitignored for this reason.
#
# COORDINATE FRAME: This project uses ENU (East-North-Up) exclusively.
# - X-axis: East (positive direction)
# - Y-axis: North (positive direction)
# - Z-axis: Up (positive direction, gravity in -Z)
# See docs/environment.md for details. Do NOT configure alternate frames.
#
# For complete documentation, see: docs/environment.md
# For training configuration, see: docs/training.md

# =============================================================================
# DIRECTORY PATHS
# =============================================================================
# Directory for storing training/evaluation logs
# Default: experiments/logs (relative to project root)
# Cross-platform: Use forward slashes (/) - they work on Windows, Linux, macOS
LOG_DIR=experiments/logs

# Directory for storing evaluation reports and plots
# Default: reports (relative to project root)
RESULTS_DIR=reports

# Directory for storing model checkpoints
# Default: checkpoints (relative to project root)
CHECKPOINT_DIR=checkpoints

# Directory for storing controller auto-tuning results
# Default: reports/tuning (relative to project root)
# Used by: scripts/controller_autotune.py
TUNING_OUTPUT_DIR=reports/tuning

# =============================================================================
# CONTROLLER CONFIGURATION
# =============================================================================
# Root directory for controller YAML configuration files
# Use this to specify a custom location for controller configs without
# modifying code. If not set, defaults to experiments/configs/
# CONTROLLER_CONFIG_ROOT=experiments/configs

# Default controller type for evaluation and training
# Options: deep, pid, lqr, riccati_lqr
# Default: deep (for training), pid (for evaluation)
# Note: CLI --controller flag overrides this value
# QUADCOPTER_DEFAULT_CONTROLLER=riccati_lqr

# =============================================================================
# RICCATI-LQR CONTROLLER SETTINGS
# =============================================================================
# These settings apply to the Riccati-LQR controller which solves the
# discrete-time algebraic Riccati equation (DARE) for optimal gains.
# See: docs/training.md#riccati-lqr-auto-tuning

# Enable fallback to heuristic LQR if DARE solver fails
# Default: true (recommended for robustness)
# Set to false for strict optimal-only mode (will raise error on failure)
# RICCATI_FALLBACK_ON_FAILURE=true

# Riccati solver tolerance for convergence
# Default: 1e-10
# Increase if solver is slow, decrease for higher precision
# RICCATI_SOLVER_TOLERANCE=1e-10

# =============================================================================
# RANDOM SEED & REPRODUCIBILITY
# =============================================================================
# Random seed for reproducible experiments
# Default: 42
QUADCOPTER_SEED=42

# =============================================================================
# EPISODE CONFIGURATION
# =============================================================================
# Episode duration in seconds
# Default: 30.0
QUADCOPTER_EPISODE_LENGTH=30.0

# Simulation timestep in seconds
# Default: 0.01
# Note: Riccati-LQR requires this to match the dt in YAML config
QUADCOPTER_DT=0.01

# =============================================================================
# QUADCOPTER PHYSICS
# =============================================================================
# Quadcopter mass in kilograms
# Default: 1.0
# Used for hover thrust calculation: hover_thrust = mass × gravity
# QUADCOPTER_MASS=1.0

# Gravitational acceleration in m/s²
# Default: 9.81
# QUADCOPTER_GRAVITY=9.81

# =============================================================================
# TARGET MOTION PARAMETERS
# =============================================================================
# Radius requirement in meters - quadcopter must be within this distance
# to count as "on-target" for success metric computation
# Default: 0.5
QUADCOPTER_TARGET_RADIUS=0.5

# Target motion type: stationary, linear, circular, sinusoidal, figure8
# Default: stationary
# Note: stationary is recommended for initial testing and baseline evaluation
QUADCOPTER_TARGET_MOTION_TYPE=stationary

# Target movement speed in meters/second
# Default: 1.0
# Applies to: linear, circular motion types
QUADCOPTER_TARGET_SPEED=1.0

# Amplitude for oscillatory motion patterns (meters)
# Default: 2.0
# Applies to: sinusoidal, figure8 motion types
QUADCOPTER_TARGET_AMPLITUDE=2.0

# Frequency for oscillatory motion patterns (Hz)
# Default: 0.5
# Applies to: sinusoidal motion type
QUADCOPTER_TARGET_FREQUENCY=0.5

# =============================================================================
# SUCCESS CRITERIA
# =============================================================================
# These values define what constitutes a "successful" tracking episode
# Default success: >= 80% on-target time for episodes >= 30 seconds

# Minimum fraction of time that must be on-target (0.0 to 1.0)
# QUADCOPTER_SUCCESS_MIN_ON_TARGET=0.8

# Minimum episode duration for success evaluation (seconds)
# QUADCOPTER_SUCCESS_MIN_DURATION=30.0

# =============================================================================
# GPU / DEVICE CONFIGURATION
# =============================================================================
# Force CPU-only execution (useful for machines without GPU or for debugging)
# Set to empty string to disable GPU: CUDA_VISIBLE_DEVICES=""
# Set to specific GPU: CUDA_VISIBLE_DEVICES="0"
# Leave commented to use default PyTorch device detection
# CUDA_VISIBLE_DEVICES=

# PyTorch device selection (alternative to CUDA_VISIBLE_DEVICES)
# Options: cpu, cuda, cuda:0, cuda:1, etc.
# Leave commented for auto-detection
# TORCH_DEVICE=cpu

# =============================================================================
# MATPLOTLIB CONFIGURATION (for headless servers)
# =============================================================================
# Set backend for servers without display (e.g., CI/CD, remote servers)
# Options: Agg (no display), TkAgg (default with display), Qt5Agg, etc.
# Required: Set MPLBACKEND=Agg for headless operation
# MPLBACKEND=Agg

# =============================================================================
# OPTIONAL: EXPERIMENT TRACKING INTEGRATION
# =============================================================================
# These are OPTIONAL integrations for experiment tracking services.
# Note: These integrations are placeholder only - not fully implemented.
#
# SECURITY WARNING: Never commit real API keys or credentials!
# - Store sensitive values ONLY in your local .env file
# - The .env file is gitignored and should never be committed
# - For CI/CD: use secret injection from your CI provider
# - For production: use secret management (Vault, AWS Secrets Manager, etc.)

# Weights & Biases (wandb) - optional experiment tracking
# Get your API key from: https://wandb.ai/settings
# WANDB_API_KEY=your_key_here
# WANDB_PROJECT=quadcopter-tracking
# WANDB_ENTITY=your_username_or_team

# MLflow - optional experiment tracking
# MLFLOW_TRACKING_URI=http://localhost:5000
# MLFLOW_EXPERIMENT_NAME=quadcopter-tracking

# TensorBoard - log directory for TensorBoard visualization
# TENSORBOARD_LOG_DIR=runs

# =============================================================================
# LOW-RESOURCE / CPU-ONLY OVERRIDES
# =============================================================================
# For machines lacking GPU acceleration, use these settings to reduce workload.
# Uncomment and adjust as needed.
# See: docs/training.md#low-resource--cpu-only-training
#
# Reduce batch size for lower memory usage:
# QUADCOPTER_BATCH_SIZE=8
#
# Use fewer episodes per epoch for faster iteration:
# QUADCOPTER_EPISODES_PER_EPOCH=3
#
# Shorter episodes for faster feedback:
# QUADCOPTER_EPISODE_LENGTH=10.0
#
# Smaller network (override via config file is preferred):
# QUADCOPTER_HIDDEN_SIZES=32,32

# =============================================================================
# FEEDFORWARD CONFIGURATION
# =============================================================================
# These settings control the feedforward behavior for PID/LQR/Riccati-LQR
# controllers. Feedforward helps track moving targets by anticipating motion.
# See: docs/results.md#feedforward-troubleshooting
#
# All three controller families (PID, LQR, Riccati-LQR) share the same
# feedforward schema. The Riccati-LQR controller additionally tracks saturation
# events when feedforward causes output clamping.

# Enable feedforward for moving target tracking
# Default: false (disabled for backward compatibility)
# Set to true when tracking linear, circular, or other moving targets
# QUADCOPTER_FEEDFORWARD_ENABLED=false

# Velocity feedforward gain (scales target velocity contribution in D term)
# Default: 0.0,0.0,0.0 (disabled)
# Recommended: 0.0-0.3 for each axis when enabled
# Format: x,y,z gains (comma-separated)
# QUADCOPTER_FF_VELOCITY_GAIN=0.0,0.0,0.0

# Acceleration feedforward gain (adds target acceleration to control output)
# Default: 0.0,0.0,0.0 (disabled)
# Recommended: 0.05-0.2 for X/Y, 0.0 for Z (vertical already handled)
# Format: x,y,z gains (comma-separated)
# QUADCOPTER_FF_ACCELERATION_GAIN=0.0,0.0,0.0

# Maximum velocity for feedforward clamping (m/s)
# Prevents oscillation from noisy velocity estimates
# Default: 10.0
# QUADCOPTER_FF_MAX_VELOCITY=10.0

# Maximum acceleration for feedforward clamping (m/s²)
# Prevents oscillation from noisy acceleration estimates
# Default: 5.0
# QUADCOPTER_FF_MAX_ACCELERATION=5.0

# Enable feedforward diagnostics logging
# When true, controller.get_control_components() returns detailed FF terms
# Useful for debugging feedforward behavior
# Default: false (minimal overhead)
# QUADCOPTER_FF_DIAGNOSTICS=false

# =============================================================================
# TUNING CONFIGURATION
# =============================================================================
# These settings control the auto-tuning behavior for PID/LQR/Riccati-LQR
# See: docs/training.md#pid-auto-tuning

# Number of tuning iterations (configurations to evaluate)
# Default: 50
# Reduce for faster tuning, increase for better coverage
# For CMA-ES, recommend at least 10 * num_parameters
# TUNING_MAX_ITERATIONS=50

# Number of evaluation episodes per configuration
# Default: 5
# Reduce for faster tuning (less accurate), increase for more stable results
# TUNING_EPISODES=5

# Tuning search strategy: random, grid, cma_es
# Default: random
# random: uniform random sampling (faster for large spaces)
# grid: exhaustive grid search (more thorough for small spaces)
# cma_es: CMA-ES black-box optimization (adaptive, good for complex landscapes)
# TUNING_STRATEGY=random

# =============================================================================
# CMA-ES SPECIFIC SETTINGS
# =============================================================================
# These settings apply when using strategy=cma_es
# See: docs/training.md#cma-es-auto-tuning

# Initial standard deviation for CMA-ES (fraction of parameter range)
# Default: 0.3
# Lower values (0.1-0.2): more local search
# Higher values (0.3-0.5): more exploration
# TUNING_CMA_SIGMA0=0.3

# CMA-ES population size (solutions per generation)
# Default: auto-calculated based on dimension
# Increase for noisy objectives or harder problems
# TUNING_CMA_POPSIZE=
